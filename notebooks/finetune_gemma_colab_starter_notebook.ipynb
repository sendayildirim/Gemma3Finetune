{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "139paaxf08Ox"
      },
      "source": [
        "# Gemma-3-1B Fine-Tuning: QLoRA vs GaLore Comparison\n",
        "\n",
        "Bu notebook Gemma-3-1b-it modelini QLoRA ve GaLore teknikleri ile fine-tune eder ve karşılaştırır.\n",
        "\n",
        "**Gereksinimler:**\n",
        "- Colab Pro (GPU ve high RAM)\n",
        "- HuggingFace token (Gemma model erişimi için)\n",
        "\n",
        "**Runtime Ayarları:**\n",
        "- Runtime > Change runtime type > GPU (T4 veya A100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WiWinGe008Oy"
      },
      "source": [
        "## 1. Setup - GitHub Clone ve Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e9qfFQ0y08Oy"
      },
      "outputs": [],
      "source": [
        "# GitHub repository clone\n",
        "import os\n",
        "\n",
        "if not os.path.exists('/content/Gemma-Finetune'):\n",
        "    print(\"Repository clone ediliyor\")\n",
        "    !git clone https://github.com/sendayildirim/Gemma-Finetune\n",
        "    print(\"Clone tamamlandi\")\n",
        "else:\n",
        "    print(\"Repository zaten mevcut\")\n",
        "\n",
        "# Working directory\n",
        "os.chdir('/content/Gemma-Finetune')\n",
        "print(f\"Working directory: {os.getcwd()}\")\n",
        "\n",
        "\n",
        "\n",
        "import sys\n",
        "sys.path.insert(0, '/content/Gemma-Finetune')\n",
        "\n",
        "!pip install -q -r requirements.txt\n",
        "\n",
        "print(\"Dependencies yuklendi\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "library-versions"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import torch\n",
        "import transformers\n",
        "import datasets\n",
        "import peft\n",
        "import trl\n",
        "import accelerate\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from huggingface_hub import login\n",
        "import json\n",
        "import gc\n",
        "\n",
        "login(new_session=False)\n",
        "\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "seed-section"
      },
      "source": [
        "## 1.5 Reproducibility - Seed Initialization\n",
        "\n",
        "Tüm random işlemlerin reproducible olması için seed=42 kullanılır."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "seed-initialization"
      },
      "outputs": [],
      "source": [
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "\n",
        "torch.manual_seed(SEED)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(SEED)\n",
        "    torch.cuda.manual_seed_all(SEED)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qzLyK8P08Oy"
      },
      "source": [
        "## 2. Dataset Hazirlama ve Onizleme"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f54a39KE08Oy"
      },
      "outputs": [],
      "source": [
        "from src.data.prepare_datasets import DatasetPreparer\n",
        "from src.config.data_config import get_data_config\n",
        "\n",
        "config = get_data_config()\n",
        "preparer = DatasetPreparer(config)\n",
        "\n",
        "print(\"Dataset preparer hazir\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bcT_Og6-08Oz"
      },
      "outputs": [],
      "source": [
        "print(\"Dataset'ler indiriliyor ve sample'lar aliniyor\")\n",
        "\n",
        "train_dataset, test_dataset = preparer.prepare_all_datasets()\n",
        "\n",
        "print(f\"\\nToplam train samples: {len(train_dataset)}\")\n",
        "print(f\"Toplam test samples: {len(test_dataset)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W6-NO7_K08Oz"
      },
      "outputs": [],
      "source": [
        "preparer.save_datasets(train_dataset, test_dataset)\n",
        "print(\"Dataset'ler kaydedildi\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0vevgiHq08Oz"
      },
      "outputs": [],
      "source": [
        "for source in [\"alpaca\", \"tulu\", \"ultrachat\"]:\n",
        "    source_samples = train_dataset.filter(lambda x: x[\"source_dataset\"] == source)\n",
        "\n",
        "    print(f\"{source.upper()} Dataset Örnek\")\n",
        "\n",
        "    if len(source_samples) > 0:\n",
        "        sample = source_samples[0]\n",
        "        for key, value in sample.items():\n",
        "            if isinstance(value, str) and len(value) > 200:\n",
        "                print(f\"{key}: {value[:200]}\")\n",
        "            else:\n",
        "                print(f\"{key}: {value}\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r8xy6HSN08Oz"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "source_counts = {}\n",
        "for sample in train_dataset:\n",
        "    source = sample[\"source_dataset\"]\n",
        "    source_counts[source] = source_counts.get(source, 0) + 1\n",
        "\n",
        "print(\"Dataset dagilimlari:\")\n",
        "for source, count in source_counts.items():\n",
        "    print(f\"  {source}: {count} samples\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_T6C3cSy08Oz"
      },
      "source": [
        "## 3. Preprocessing - Gemma Chat Template"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "brXZSXB308Oz"
      },
      "outputs": [],
      "source": [
        "from src.data.preprocess import DatasetPreprocessor\n",
        "\n",
        "preprocessor = DatasetPreprocessor(config)\n",
        "\n",
        "print(\"Preprocessor hazir\")\n",
        "print(f\"Tokenizer: {preprocessor.tokenizer.name_or_path}\");"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k0OdLFWG08Oz"
      },
      "outputs": [],
      "source": [
        "print(\"Dataset'ler Gemma chat template'ine cevriliyor\")\n",
        "\n",
        "train_processed, test_processed = preprocessor.load_and_preprocess()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VYlftq8W08Oz"
      },
      "outputs": [],
      "source": [
        "print(\"PREPROCESSED ORNEK (Gemma Chat Format)\")\n",
        "print(train_processed[0][\"text\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "03btx-_708Oz"
      },
      "outputs": [],
      "source": [
        "preprocessor.save_processed_datasets(train_processed, test_processed)\n",
        "\n",
        "print(\"Preprocessed dataset'ler kaydedildi\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"GEMMA CHAT TEMPLATE FORMAT ORNEKLERI\")\n",
        "\n",
        "examples_dir = \"./data/processed/examples\"\n",
        "\n",
        "for source in [\"alpaca\", \"tulu\", \"ultrachat\"]:\n",
        "    example_file = os.path.join(examples_dir, f\"{source}_example.txt\")\n",
        "\n",
        "    if os.path.exists(example_file):\n",
        "        print(f\"{source.upper()} Dataset - Gemma Format:\")\n",
        "\n",
        "        with open(example_file, \"r\", encoding=\"utf-8\") as f:\n",
        "            content = f.read()\n",
        "            if len(content) > 600:\n",
        "                print(content[:600] + \"\\n...\")\n",
        "            else:\n",
        "                print(content)\n",
        "    else:\n",
        "        print(f\"{source} example dosyasi bulunamadi\")"
      ],
      "metadata": {
        "id": "3faMFAY2ooXX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tuaXGWbS08Oz"
      },
      "source": [
        "## 4. Base Model Evaluation (Baseline)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qpNxbonN08Oz"
      },
      "outputs": [],
      "source": [
        "from src.evaluation.evaluate_base import BaseModelEvaluator\n",
        "\n",
        "base_evaluator = BaseModelEvaluator(model_name=config.model_name)\n",
        "\n",
        "print(\"Base model evaluator hazir\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_rKuZrKb08Oz"
      },
      "outputs": [],
      "source": [
        "import importlib\n",
        "if 'src.evaluation.evaluate_base' in sys.modules:\n",
        "    del sys.modules['src.evaluation.evaluate_base']\n",
        "    from src.evaluation.evaluate_base import BaseModelEvaluator\n",
        "    base_evaluator = BaseModelEvaluator(model_name=config.model_name)\n",
        "    print(\"Module reloaded - batch processing aktif!\")\n",
        "\n",
        "print(\"Base model yukleniyor\")\n",
        "base_evaluator.load_model()\n",
        "\n",
        "print(\"Model yuklendi\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "__O0m1cs08Oz"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "print(\"Base model evaluation basliyor\")\n",
        "print( \"Burada GPU RAM 2.6'dan 26.1'e çıktı\")\n",
        "\n",
        "test_dataset_path = \"./data/processed/test_processed.json\"\n",
        "start_time = time.time()\n",
        "base_results = base_evaluator.evaluate_on_test_set(\n",
        "    test_dataset_path,\n",
        "    max_samples=1000\n",
        ")\n",
        "elapsed_time = time.time() - start_time\n",
        "elapsed_minutes = elapsed_time / 60\n",
        "print(\"Base Model Results:\")\n",
        "print(f\"BLEU-4: {base_results['bleu_4']:.4f}\")\n",
        "print(f\"ROUGE-L: {base_results['rouge_l']:.4f}\")\n",
        "print(f\"Evaluation completed in {elapsed_minutes:.2f} minutes\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CBITnd-Y08Oz"
      },
      "outputs": [],
      "source": [
        "with open('results/metrics/base_model_examples.json', 'r') as f:\n",
        "    examples = json.load(f)\n",
        "\n",
        "print(\"BASE MODEL ORNEK GENERATION'LAR:\")\n",
        "\n",
        "for i, ex in enumerate(examples[:3], 1):\n",
        "    print(f\"Ornek {i}:\")\n",
        "    print(f\"Instruction: {ex['instruction'][:10000]}\")\n",
        "    print(f\"Expected: {ex['expected'][:10000]}\")\n",
        "    print(f\"Generated: {ex['generated'][:10000]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hCjC-JxP08Oz"
      },
      "outputs": [],
      "source": [
        "del base_evaluator\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "print(\"Memory temizlendi\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hyperparameter-section"
      },
      "source": [
        "## 4.5 Hyperparameter Configuration Comparison\n",
        "\n",
        "Bu hücre QLoRA ve GaLore tekniklerinin hyperparameter'larını karşılaştırır.\n",
        "Report için gerekli comparison table'ı oluşturur."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hyperparameter-comparison"
      },
      "outputs": [],
      "source": [
        "from src.config.qlora_config import get_qlora_config\n",
        "from src.config.galore_config import get_galore_config\n",
        "\n",
        "qlora_cfg = get_qlora_config()\n",
        "galore_cfg = get_galore_config()\n",
        "\n",
        "comparison_data = {\n",
        "    'Hyperparameter': [\n",
        "        'Epochs',\n",
        "        'Batch Size (per device)',\n",
        "        'Gradient Accumulation',\n",
        "        'Effective Batch Size',\n",
        "        'Learning Rate',\n",
        "        'Weight Decay',\n",
        "        'Warmup Steps',\n",
        "        'Max Sequence Length',\n",
        "        'Optimizer',\n",
        "        'LR Scheduler',\n",
        "        'Precision',\n",
        "        'Gradient Checkpointing',\n",
        "        'Max Grad Norm',\n",
        "        'Random Seed'\n",
        "    ],\n",
        "    'QLoRA': [\n",
        "        qlora_cfg.num_train_epochs,\n",
        "        qlora_cfg.per_device_train_batch_size,\n",
        "        qlora_cfg.gradient_accumulation_steps,\n",
        "        qlora_cfg.per_device_train_batch_size * qlora_cfg.gradient_accumulation_steps,\n",
        "        qlora_cfg.learning_rate,\n",
        "        qlora_cfg.weight_decay,\n",
        "        qlora_cfg.warmup_steps,\n",
        "        qlora_cfg.max_seq_length,\n",
        "        qlora_cfg.optim,\n",
        "        qlora_cfg.lr_scheduler_type,\n",
        "        'BF16' if qlora_cfg.bf16 else ('FP16' if qlora_cfg.fp16 else 'FP32'),\n",
        "        'Yes' if qlora_cfg.gradient_checkpointing else 'No',\n",
        "        qlora_cfg.max_grad_norm,\n",
        "        qlora_cfg.seed\n",
        "    ],\n",
        "    'GaLore': [\n",
        "        galore_cfg.num_train_epochs,\n",
        "        galore_cfg.per_device_train_batch_size,\n",
        "        galore_cfg.gradient_accumulation_steps,\n",
        "        galore_cfg.per_device_train_batch_size * galore_cfg.gradient_accumulation_steps,\n",
        "        galore_cfg.learning_rate,\n",
        "        galore_cfg.weight_decay,\n",
        "        galore_cfg.warmup_steps,\n",
        "        galore_cfg.max_seq_length,\n",
        "        galore_cfg.optim,\n",
        "        galore_cfg.lr_scheduler_type,\n",
        "        'BF16' if galore_cfg.bf16 else ('FP16' if galore_cfg.fp16 else 'FP32'),\n",
        "        'Yes' if galore_cfg.gradient_checkpointing else 'No',\n",
        "        galore_cfg.max_grad_norm,\n",
        "        galore_cfg.seed\n",
        "    ],\n",
        "    'Rationale': [\n",
        "        'Sufficient for convergence',\n",
        "        'Memory constraint',\n",
        "        'Memory optimization',\n",
        "        'Effective batch size',\n",
        "        'Adjusted for technique',\n",
        "        'Regularization',\n",
        "        'Learning rate warmup',\n",
        "        'Gemma context window',\n",
        "        'Technique-specific',\n",
        "        'Smooth decay',\n",
        "        'Numerical stability',\n",
        "        'Memory optimization',\n",
        "        'Gradient clipping',\n",
        "        'Reproducibility'\n",
        "    ]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(comparison_data)\n",
        "\n",
        "print(\"HYPERPARAMETER COMPARISON TABLE\")\n",
        "print(df.to_string(index=False))\n",
        "\n",
        "print(\"TECHNIQUE-SPECIFIC PARAMETERS:\")\n",
        "print(\"QLoRA:\")\n",
        "print(f\"  - LoRA rank (r): {qlora_cfg.lora_r}\")\n",
        "print(f\"  - LoRA alpha: {qlora_cfg.lora_alpha}\")\n",
        "print(f\"  - LoRA dropout: {qlora_cfg.lora_dropout}\")\n",
        "print(f\"  - Target modules: {qlora_cfg.target_modules}\")\n",
        "print(f\"  - 4-bit quantization: {qlora_cfg.load_in_4bit}\")\n",
        "print(f\"  - Quantization type: {qlora_cfg.bnb_4bit_quant_type}\")\n",
        "\n",
        "print(\"GaLore:\")\n",
        "print(f\"  - Rank: {galore_cfg.rank}\")\n",
        "print(f\"  - Update projection gap: {galore_cfg.update_proj_gap}\")\n",
        "print(f\"  - GaLore scale: {galore_cfg.galore_scale}\")\n",
        "print(f\"  - Projection type: {galore_cfg.proj_type}\")\n",
        "print(f\"  - Target modules: {galore_cfg.target_modules_list}\")\n",
        "\n",
        "\n",
        "os.makedirs('results/metrics', exist_ok=True)\n",
        "df.to_csv('results/metrics/hyperparameter_comparison.csv', index=False)\n",
        "print(\"Table saved to: results/metrics/hyperparameter_comparison.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQj_WRlD08Oz"
      },
      "source": [
        "## 5. QLoRA Fine-Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nnUSr-hZ08Oz"
      },
      "outputs": [],
      "source": [
        "from src.config.qlora_config import get_qlora_config\n",
        "\n",
        "qlora_config = get_qlora_config()\n",
        "\n",
        "print(\"QLoRA Konfigurasyonu:\")\n",
        "print(f\"  Model: {qlora_config.model_name}\")\n",
        "print(f\"  LoRA rank: {qlora_config.lora_r}\")\n",
        "print(f\"  LoRA alpha: {qlora_config.lora_alpha}\")\n",
        "print(f\"  Learning rate: {qlora_config.learning_rate}\")\n",
        "print(f\"  Epochs: {qlora_config.num_train_epochs}\")\n",
        "print(f\"  Batch size: {qlora_config.per_device_train_batch_size}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BvQiYCti08Oz"
      },
      "outputs": [],
      "source": [
        "from src.training.train_qlora import train\n",
        "\n",
        "print(\"QLoRA TRAINING BASLIYOR\")\n",
        "\n",
        "train(qlora_config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J2O3aZTg08Oz"
      },
      "outputs": [],
      "source": [
        "with open('results/metrics/qlora_metrics.json', 'r') as f:\n",
        "    qlora_metrics = json.load(f)\n",
        "\n",
        "print(\"QLoRA Training Metrikleri:\")\n",
        "print(f\"  Peak Memory: {qlora_metrics['memory_stats']['peak_memory_allocated_gb']:.2f} GB\")\n",
        "print(f\"  Training Time: {qlora_metrics['training_time_hours']:.2f} hours\")\n",
        "print(f\"  Config: {json.dumps(qlora_metrics['config'], indent=2)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V6WG6Ja708Oz"
      },
      "outputs": [],
      "source": [
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "print(\"Memory temizlendi\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9FOy1egS08Oz"
      },
      "source": [
        "## 6. GaLore Fine-Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z7l2gubL08Oz"
      },
      "outputs": [],
      "source": [
        "from src.config.galore_config import get_galore_config\n",
        "\n",
        "galore_config = get_galore_config()\n",
        "\n",
        "print(\"GaLore Konfigurasyonu:\")\n",
        "print(f\"  Model: {galore_config.model_name}\")\n",
        "print(f\"  Rank: {galore_config.rank}\")\n",
        "print(f\"  Update projection gap: {galore_config.update_proj_gap}\")\n",
        "print(f\"  Learning rate: {galore_config.learning_rate}\")\n",
        "print(f\"  Epochs: {galore_config.num_train_epochs}\")\n",
        "print(f\"  Batch size: {galore_config.per_device_train_batch_size}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MBifm0Kh08Oz"
      },
      "outputs": [],
      "source": [
        "from src.training.train_galore import train as train_galore\n",
        "\n",
        "print(\"GALORE TRAINING BASLIYOR\")\n",
        "print(\"Bu islem 2-4 saat surebilir\")\n",
        "\n",
        "train_galore(galore_config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "__9ZpR7108Oz"
      },
      "outputs": [],
      "source": [
        "with open('results/metrics/galore_metrics.json', 'r') as f:\n",
        "    galore_metrics = json.load(f)\n",
        "\n",
        "print(\"GaLore Training Metrikleri:\")\n",
        "print(f\"  Peak Memory: {galore_metrics['memory_stats']['peak_memory_allocated_gb']:.2f} GB\")\n",
        "print(f\"  Training Time: {galore_metrics['training_time_hours']:.2f} hours\")\n",
        "print(f\"  Config: {json.dumps(galore_metrics['config'], indent=2)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eqovtXrW08Oz"
      },
      "outputs": [],
      "source": [
        "# Memory temizle\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "print(\"Memory temizlendi\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNHGUIQR08O0"
      },
      "source": [
        "## 7. Fine-Tuned Models Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zct8aDh708O0"
      },
      "outputs": [],
      "source": [
        "# Module'u reload et (yeni batch processing icin)\n",
        "import importlib\n",
        "if 'src.evaluation.evaluate_models' in sys.modules:\n",
        "    del sys.modules['src.evaluation.evaluate_models']\n",
        "\n",
        "from src.evaluation.evaluate_models import FineTunedModelEvaluator\n",
        "import time\n",
        "\n",
        "print(\"QLoRA model evaluation basliyor (batch processing aktif)\\n\")\n",
        "\n",
        "qlora_evaluator = FineTunedModelEvaluator(\n",
        "    technique=\"QLoRA\",\n",
        "    model_path=\"./models/qlora/final\",\n",
        "    base_model_name=config.model_name\n",
        ")\n",
        "\n",
        "qlora_evaluator.load_model()\n",
        "\n",
        "start_time = time.time()\n",
        "qlora_eval_results = qlora_evaluator.evaluate_on_test_set(\n",
        "    test_dataset_path=\"./data/processed/test_processed.json\",\n",
        "    max_samples=500\n",
        ")\n",
        "elapsed_time = time.time() - start_time\n",
        "elapsed_minutes = elapsed_time / 60\n",
        "\n",
        "print(\"\\nQLoRA Evaluation Results:\")\n",
        "print(f\"BLEU-4: {qlora_eval_results['bleu_4']:.4f}\")\n",
        "print(f\"ROUGE-L: {qlora_eval_results['rouge_l']:.4f}\")\n",
        "print(f\"Evaluation completed in {elapsed_minutes:.2f} minutes\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8vZXQVOe08O0"
      },
      "outputs": [],
      "source": [
        "del qlora_evaluator\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oWjPN5kg08O0"
      },
      "outputs": [],
      "source": [
        "# Module'u reload et (yeni batch processing icin)\n",
        "import importlib\n",
        "if 'src.evaluation.evaluate_models' in sys.modules:\n",
        "    del sys.modules['src.evaluation.evaluate_models']\n",
        "\n",
        "from src.evaluation.evaluate_models import FineTunedModelEvaluator\n",
        "import time\n",
        "\n",
        "print(\"GaLore model evaluation basliyor (batch processing aktif)\\n\")\n",
        "\n",
        "galore_evaluator = FineTunedModelEvaluator(\n",
        "    technique=\"GaLore\",\n",
        "    model_path=\"./models/galore/final\",\n",
        "    base_model_name=config.model_name\n",
        ")\n",
        "\n",
        "galore_evaluator.load_model()\n",
        "\n",
        "start_time = time.time()\n",
        "galore_eval_results = galore_evaluator.evaluate_on_test_set(\n",
        "    test_dataset_path=\"./data/processed/test_processed.json\",\n",
        "    max_samples=500\n",
        ")\n",
        "elapsed_time = time.time() - start_time\n",
        "elapsed_minutes = elapsed_time / 60\n",
        "\n",
        "print(\"\\nGaLore Evaluation Results:\")\n",
        "print(f\"BLEU-4: {galore_eval_results['bleu_4']:.4f}\")\n",
        "print(f\"ROUGE-L: {galore_eval_results['rouge_l']:.4f}\")\n",
        "print(f\"Evaluation completed in {elapsed_minutes:.2f} minutes\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zP4aT57h08O0"
      },
      "outputs": [],
      "source": [
        "del galore_evaluator\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JGJ7KBcS08O0"
      },
      "source": [
        "## 8. Results Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xVF0ckAE08O0"
      },
      "outputs": [],
      "source": [
        "from src.evaluation.visualize_results import ResultsVisualizer\n",
        "\n",
        "visualizer = ResultsVisualizer()\n",
        "visualizer.load_results()\n",
        "\n",
        "print(\"Results yuklendi\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B8l4j0LP08O0"
      },
      "outputs": [],
      "source": [
        "comparison_df = visualizer.create_comparison_table()\n",
        "\n",
        "print(\"ASSESSMENT REPORTING TABLE\")\n",
        "print(comparison_df.to_string(index=False))\n",
        "\n",
        "# Delta hesaplamalari\n",
        "print(\"IMPROVEMENT ANALYSIS\")\n",
        "\n",
        "for idx, row in comparison_df.iterrows():\n",
        "    technique = row['Technique']\n",
        "\n",
        "    try:\n",
        "        bleu_before = float(row['BLEU-4 (Before)'])\n",
        "        bleu_after = float(row['BLEU-4 (After)'])\n",
        "        rouge_before = float(row['ROUGE-L (Before)'])\n",
        "        rouge_after = float(row['ROUGE-L (After)'])\n",
        "\n",
        "        bleu_improvement = ((bleu_after - bleu_before) / bleu_before) * 100\n",
        "        rouge_improvement = ((rouge_after - rouge_before) / rouge_before) * 100\n",
        "\n",
        "        print(f\"\\n{technique}:\")\n",
        "        print(f\"  BLEU-4 Improvement: {bleu_improvement:+.2f}%\")\n",
        "        print(f\"  ROUGE-L Improvement: {rouge_improvement:+.2f}%\")\n",
        "        print(f\"  Peak Memory: {row['Peak Memory (GB)']} GB\")\n",
        "        print(f\"  Training Time: {row['Training Time (Hrs)']} hours\")\n",
        "    except (ValueError, ZeroDivisionError):\n",
        "        print(f\"\\n{technique}: Data not available yet\")\n",
        "\n",
        "\n",
        "print(\"MARKDOWN FORMAT that I used in report.md):\")\n",
        "print(\"```\")\n",
        "print(comparison_df.to_markdown(index=False))\n",
        "print(\"```\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AvTLjD5808O0"
      },
      "outputs": [],
      "source": [
        "# BLEU/ROUGE comparison plot\n",
        "visualizer.plot_bleu_rouge_comparison()\n",
        "\n",
        "from IPython.display import Image, display\n",
        "display(Image('results/plots/bleu_rouge_comparison.png'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "35r4mqW408O0"
      },
      "outputs": [],
      "source": [
        "# Memory vs Performance plot\n",
        "visualizer.plot_memory_vs_performance()\n",
        "\n",
        "display(Image('results/plots/memory_vs_performance.png'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EoXzwVmT08O0"
      },
      "outputs": [],
      "source": [
        "# Summary report\n",
        "visualizer.create_summary_report()\n",
        "\n",
        "with open('results/summary_report.txt', 'r') as f:\n",
        "    print(f.read())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmPH6Lnb08O0"
      },
      "source": [
        "## 9. Side-by-Side Example Generations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uvzxt9Te08O0"
      },
      "outputs": [],
      "source": [
        "with open('results/metrics/base_model_examples.json', 'r') as f:\n",
        "    base_examples = json.load(f)\n",
        "\n",
        "with open('results/metrics/qlora_examples.json', 'r') as f:\n",
        "    qlora_examples = json.load(f)\n",
        "\n",
        "with open('results/metrics/galore_examples.json', 'r') as f:\n",
        "    galore_examples = json.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "glCKMXWo08O0"
      },
      "outputs": [],
      "source": [
        "num_examples = min(10, len(base_examples))\n",
        "\n",
        "for i in range(num_examples):\n",
        "    print(\"=\"*100)\n",
        "    print(f\"EXAMPLE {i+1}\")\n",
        "    print(\"=\"*100)\n",
        "\n",
        "    print(f\"\\n[INSTRUCTION]\")\n",
        "    print(base_examples[i]['instruction'])\n",
        "\n",
        "    print(f\"\\n[EXPECTED RESPONSE]\")\n",
        "    print(base_examples[i]['expected'])\n",
        "\n",
        "    print(f\"\\n[BASE MODEL]\")\n",
        "    print(base_examples[i]['generated'])\n",
        "\n",
        "    print(f\"\\n[QLORA MODEL]\")\n",
        "    print(qlora_examples[i]['generated'])\n",
        "\n",
        "    print(f\"\\n[GALORE MODEL]\")\n",
        "    print(galore_examples[i]['generated'])\n",
        "\n",
        "    print(\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jjcfiy6h08O0"
      },
      "source": [
        "## 10. Final Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M4yK3YeZ08O0"
      },
      "outputs": [],
      "source": [
        "print(\"1. DATASET:\")\n",
        "print(f\"   - Train samples: {len(train_processed)}\")\n",
        "print(f\"   - Test samples: {len(test_processed)}\")\n",
        "print(f\"   - Sources: Alpaca, Tulu v2, Ultrachat\")\n",
        "\n",
        "print(\"2. BASE MODEL PERFORMANCE:\")\n",
        "print(f\"   - BLEU-4: {base_results['bleu_4']:.4f}\")\n",
        "print(f\"   - ROUGE-L: {base_results['rouge_l']:.4f}\")\n",
        "\n",
        "print(\"3. QLORA:\")\n",
        "print(f\"   - BLEU-4: {qlora_eval_results['bleu_4']:.4f}\")\n",
        "print(f\"   - ROUGE-L: {qlora_eval_results['rouge_l']:.4f}\")\n",
        "print(f\"   - Peak Memory: {qlora_metrics['memory_stats']['peak_memory_allocated_gb']:.2f} GB\")\n",
        "print(f\"   - Training Time: {qlora_metrics['training_time_hours']:.2f} hours\")\n",
        "\n",
        "print(\"4. GALORE:\")\n",
        "print(f\"   - BLEU-4: {galore_eval_results['bleu_4']:.4f}\")\n",
        "print(f\"   - ROUGE-L: {galore_eval_results['rouge_l']:.4f}\")\n",
        "print(f\"   - Peak Memory: {galore_metrics['memory_stats']['peak_memory_allocated_gb']:.2f} GB\")\n",
        "print(f\"   - Training Time: {galore_metrics['training_time_hours']:.2f} hours\")\n",
        "\n",
        "print(\"5. CIKTILAR:\")\n",
        "print(\"   - Comparison Table: results/metrics/comparison_table.csv\")\n",
        "print(\"   - Plots: results/plots/\")\n",
        "print(\"   - Examples: results/metrics/*_examples.json\")\n",
        "print(\"   - Summary: results/summary_report.txt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PjHJDsjW08O0"
      },
      "outputs": [],
      "source": [
        "print(\"Kaydedilen dosyalar:\")\n",
        "for root, dirs, files in os.walk('results/'):\n",
        "    for file in files:\n",
        "        filepath = os.path.join(root, file)\n",
        "        print(f\"  {filepath}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "finetune_gemma_colab.ipynb",
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}